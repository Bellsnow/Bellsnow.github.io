---
title: "Algospot/HABIT"
tags: [Suffix Array, LCP Array]
---
# HABIT 

> Source Codes: [HABIT](https://github.com/Bellsnow/ProblemSolving/tree/master/00_AlgoSpot/HABIT)  

## Complexity
* Time
	* habit.c: $O(n^2)$ (Suffix Array: $O(n\log^2n)$, Common Prefix: $O(n^2)$)
	* habit_kasai.c: $O(n\log^2n)$ (Suffix Array: $O(n\log^2n)$, LCP Array: $O(n)$)
	* Most Optimized: $O(n)$
* Space
	* habit.c, habit_kasai.c: $O(n)$

## Tools
* Suffix Array(SA)  
String 내의 각 위치 기준 suffix들을 사전 순으로 정렬한 자료구조. 위치 index로 표현된다.  
Ex) "Banana"  

| Order | Index(SA) | Suffix |
| :-----: | :-----: | :------ |
| 0 | 5 | a |
| 1 | 3 | ana |
| 2 | 1 | anana |
| 3 | 0 | Banana |
| 4 | 4 | na |
| 5 | 2 | nana |{: .align-center}
  
* LCP(Longest Common Prefix) Array  
Suffix Array에서 인접한 element 간에 가장 길게 일치하는 prefix의 길이를 나타내는 자료구조.  
Suffix Array는 사전 순으로 정렬되기 때문에 인접한 element와 prefix가 가장 길게 일치한다.  
Ex) "Banana", SA[i]와 SA[i-1]를 비교하는 경우

| Order | Index(SA) | LCP | Suffix | Common Prefix |
| :-----: | :-----: | :------: | :--- | :--- | 
| 0 | 5 | 0 | a | - |
| 1 | 3 | 1 |  ana | a | 
| 2 | 1 | 3 | anana | ana |
| 3 | 0 | 0 | Banana | |
| 4 | 4 | 0 | na | |
| 5 | 2 | 2 | nana | na |{: .align-center}

## Demonstration
가장 떠올리기 쉬운 접근법은 만들 수 있는 모든 substring을 string 전체와 비교하면서 중복되는 횟수를 세는 것이다. K 회 이상인 것들 중에서 가장 긴 substring의 길이가 답이 될 것이다. 모든 substring의 개수는 string 내부에서 시작과 끝, 두 지점을 고르는 경우의 수와 같기 때문에 ${n \choose 2} = O(n^2)$이고 이 것들을 string과 비교하는데 최소 $O(n)$의 time cost가 발생하므로 전체 time complexity는 $O(n^3)$이 된다. string의 최대 길이는 4000이고 따라서 $O(n^3) \approx 6.4 \times 10^10$에서는 time limit 1s를 맞추기 어렵다.  

### Suffix Array
위 algorithm에서 개선 할 수 있는 부분은 무엇일까? 예를 들어 "Banana"의 substring, s[1:2] = "an"을 들고 전체 string인 "Banana"와 비교를 했을 때 s[3:4] = "an"과 일치하는 경우가 발생한다. 이후에 s[3:4] = "an" 혹은 s[3:5] = "ana"를 "Banana" 전체와 비교 할 필요가 있을까? 이미 s[1:2] = "an"에서 비교를 할때 s[0] = "B"의 위치에서 불일치가 발생 했을 것이다. 그렇다면 같은 prefix를 가지는 s[3:4] = "an" 혹은 s[3:5] = "ana" 역시 s[0] = "B"에서 불일치가 발생하기에 비교 할 필요가 없다. 정리하면 같은 prefix를 가지는 substring들 끼리는 다른 prefix를 가지는 substring과 중복해서 비교 될 필요가 없다.  
이때 유용한 자료구조가 Suffix Array(이하 SA)이다. SA는 string의 모든 suffix를 표현하기 때문에 각 entry의 모든 prefix의 집합은 substring의 전체 집합이다. 따라서 entry간에 모든 prefix를 비교하면 모든 substring을 비교하는 것과 같다. 이 때 SA는 string 내의 모든 suffix들을 사전 순으로 정렬했기에 *하나의 suffix와 가장 유사한(가장 긴) prefix를 공유하는 suffix는 SA 내의 인접한 entry*이다. 따라서 전체 모든 substring을 전체 string에 대해 비교 할 필요 없이 SA에서 인접한 entry의 prefix만 비교 해 나가는 것으로도 중복 substring을 빠짐 없이 찾을 수 있다.  
구체적으로 SA를 사용하여 주어진 문제를 어떻게 풀 수 있을까? 아래와 같이 어떤 string의 SA 일부분이 주어졌다고 하자.  

| Order  | Suffix |
| :-----: | :------ |
| i  | aaa |
| i+1 | aaaa |
| i+2 | aaaaa |
| i+3 | aab |{: .align-center}

i와 i+1를 비교 했을 때 공통 prefix는 "aaa"로 길이는 3이고 발생 횟수는 2회 이다. 다음 i+1과 i+2를 비교 했을 때 공통 prefix는 "aaaa"로 길이는 4이고 발생 횟수는 2회이다. 이때 "aaa"는 몇 회 발생 했을까? "aaaa"는 "aaa"를 포함하기 때문에 "aaa"는 3회 발생 하였다. i와 i+2 모두 인접한 i+1과 일치하는 부분이 있기 때문에 i와 i+2도 일치하는 부분을 가지게 되는 것이다. 이처럼 SA 내의 prefix는 연속성을 가질 수 있다.  
i+2와 i+3을 비교 했을 때 공통 prefix는 "aa"로 길이는 2이다. 발생 횟수는 어떻게 될까 i부터 "aa"를 포함 해 왔으므로 "aa"의 출현 횟수는 4회이다. 이때 "aaa"는 어떻게 될까? 발생 횟수는 i+2까지 총 3회로 마감된다. 이후에 "aaa"가 나올 수 있을까? 없다. 왜냐하면 "aaa"를 prefix로 가지는 다른 SA entry가 있다면 사전 순으로 정렬된 SA 내에서 i+3의 aab 이전에 나왔을 것이기 때문이다. 즉 "aa"는 i+3 까지 연속적으로 발생하지만 "aaa"는 더 이상 출현하지 않는다.  
따라서 SA를 순회하면서 인접한 SA entry간에 공통된 prefix의 길이를 비교하면서 같거나 늘어나면 그 이하 길이의 공통 prefix 출현 횟수도 늘리고, 공통된 prefix의 길이가 줄어들면 이 전에 출현 했던 길이가 긴 prefix의 출현 횟수 counting을 멈춰가며 기준 횟수 K와 비교하면 된다. 이렇게 진행하면서 K 회 이상으로 출현하는 가장 긴 prefix의 길이를 찾으면 되는 것이다. 간략한 code는 아래와 같다.
```c
int cur, log = 0;
if (K == 1) return len;
for(int i = 1; i < len; i++) {
    int preIdx = SA[i-1];
    int idx = SA[i];
    cur = 0;
    while(str[idx++] == str[preIdx++]) {
        if(cur >= log) cntList[cur] = 2;
        else cntList[cur]++;
        if(cntList[cur] >= K && (cur+1) > res)
            res = cur + 1;
        cur++;
	}
    log = cur;
}
return res;
```
이때 전체 SA를 순회($O(n)$)하면서 entry간에 $O(k), (k \le n)$번 비교를 진행하기에 time complexity는 $O(n^2)$이다. SA는 best로 $O(n)$으로 만들 수 있고 간단하게 $O(n\log^2n)$([Manber & Myers](https://www.geeksforgeeks.org/suffix-array-set-2-a-nlognlogn-algorithm/))으로 만들 수 있으므로 전체 complexity는 $O(n^2)$이 된다. $O(n^2) \approx 1.6 \times 10^7$로 50개의 모든 case가 worst case가 아니라면 해 볼 만하지 않을까...? 

### LCP Array
이번 문제와 같이 SA를 사용 할 때 자주 요구되는 부분이 SA entry간 공통된 prefix들이다. 특히 가장 긴 공통 prefix의 정보는 유용하게 사용되기에 이를 명명하는 자료구조를 LCP array라 한다. 그러면 LCP array를 사용하여 좀 더 효율적으로 이번 문제를 해결 할 수 있을까?  
LCP array가 준비 되어 있다면 SA를 순회하면서 LCP 정보를 stack에서 운용하면서 답을 구해 나갈 수 있다. 다음 SA entry에 대해서 현재 stack의 LCP 보다 크면 출현 횟수(2회)와 같이 push를 한다. 같으면 현재 stack에서의 횟수만 증가시킨다. 작으면 stack pop을 하면서 이전의 출현 횟수를 누적 시킨다. 간략한 code는 아래와 같다.(최적화가 필요해 보이긴 하다.)
```c
int stack[MAX_S+1][2]; int sp = 0;
if (K == 1) return len;
stack[0][0] = stack[0][1] = 0;
for (int i = 1; i < len; i++) {
	while(sp > 0 && stack[sp][0] > LCP[i]) {
		sp--;
		stack[sp][1] += stack[sp+1][1] - 1;
       	if (stack[sp][1] >= K && stack[sp][0] > res) res = stack[sp][0];
	}

   	if (stack[sp][0] < LCP[i]) {
        stack[++sp][0] = LCP[i];
        stack[sp][1] = 2;
    } else if (stack[sp][0] == LCP[i])
      	stack[sp][1]++;
	if (stack[sp][1] >= K && stack[sp][0] > res) res = stack[sp][0];
}
while(--sp > 0) {
	stack[sp][1] += stack[sp+1][1] - 1;
	if(stack[sp][1] >= K && stack[sp][0] > res) {
		res = stack[sp][0];
		break;
	}
}
return res;
```
이때 전체 SA를 순회($O(n)$)하면서 entry마다 LCP array 참조를 $O(1)$에 진행하고 각 LCP 마다 stack push/pop을 $O(1)$에 끝내기에 time complexity는 $O(n)$이다. 여기서 핵심은 LCP array를 만드는데 필요한 time cost인데 [kasai's algorithm](https://www.geeksforgeeks.org/%C2%AD%C2%ADkasais-algorithm-for-construction-of-lcp-array-from-suffix-array/)으로 LCP array를 만들면 $O(n)$으로 구성 할 수 있다. 따라서 SA를 $O(n\log^2n)$에 구성하였을 경우 전체 complexity는 $O(n\log^2n)$이다. $O(n\log^2n) \approx 5.8 \times 10^5$이므로 50개의 test case에 대해서 1s의 time limit 안에 수행이 가능하다. 

## Results
* habit.c : 620ms
* habit_kasai.c : 124ms 

## Review
* LCP array를 만드는 algorithm을 떠올리지 못했다. string의 문자 s[i]로 시작하는 LCP의 길이가 k이면 s[i+1]의 LCP 길이는 k로 표현 가능하다에서 사고가 더 이상 발전하지 못했다. SA entry는 결국 하나의 string에서 기인한다는 것을 알고 그 특징을 잘 활용 했어야 했다.